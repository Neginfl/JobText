{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b95b931-75d3-4020-ae53-0fa7712d096a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             job_title  \\\n",
      "0       ۲۶ ۱۵۳ آگهی استخدام فعال در ۱۱ ۳۲۱ شرکت ایرانی   \n",
      "1                      بهترین فرصت های شغلی در جابینجا   \n",
      "2    با رزومه ساز رایگان جابینجا، رزومه کاری حرفه ا...   \n",
      "3                    فهرست ۵۰ شرکت برتر ایران برای کار   \n",
      "4                                                  NaN   \n",
      "..                                                 ...   \n",
      "196                             ورود به حساب کارفرمایی   \n",
      "197                           سوالات متداول کارفرمایان   \n",
      "198                                         تماس با ما   \n",
      "199                                جابینجا در رسانه ها   \n",
      "200                                                      \n",
      "\n",
      "                                       content_snippet  \n",
      "0    استخدام آگهی استخدام سایت کاریابی جابینجا جابی...  \n",
      "1    فرصت های شغلی موقعیت شغلی جابینجا امکان جدید ه...  \n",
      "2    رزومه ساز ساخت رزومه رزومه ساز آنلاین جابینجا ...  \n",
      "3    فهرست ۵۰ شرکت برتر ایران برای کار جابینجا امکا...  \n",
      "4    جذب نیرو ثبت آگهی استخدام جابینجا خانه تعرفه ه...  \n",
      "..                                                 ...  \n",
      "196  ورود به حساب کارفرمایی جابینجا حساب کارفرمایی ...  \n",
      "197  سوالات متداول کارفرمایان جابینجا امکان جدید هم...  \n",
      "198  تماس با ما جابینجا امکان جدید همین حالا رزومه ...  \n",
      "199  جابینجا در رسانه ها جابینجا امکان جدید همین حا...  \n",
      "200                                      العربية فارسی  \n",
      "\n",
      "[201 rows x 2 columns]\n",
      "                              job_title  \\\n",
      "count                               176   \n",
      "unique                               45   \n",
      "top     بهترین فرصت های شغلی در جابینجا   \n",
      "freq                                129   \n",
      "\n",
      "                                          content_snippet  \n",
      "count                                                 201  \n",
      "unique                                                200  \n",
      "top     جذب نیرو ثبت آگهی استخدام جابینجا خانه تعرفه ه...  \n",
      "freq                                                    2  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "import urllib3\n",
    "import json\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import pandas as pd\n",
    "from queue import Queue\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "\n",
    "# Configure logging with a rotating file handler\n",
    "log_handler = RotatingFileHandler('jobinja_scraper.log', maxBytes=5*1024*1024, backupCount=2)\n",
    "log_handler.setLevel(logging.ERROR)\n",
    "log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "log_handler.setFormatter(log_formatter)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "logger.addHandler(log_handler)\n",
    "\n",
    "class Jobinja:\n",
    "    def __init__(self, base_url=\"https://jobinja.ir/\", save_dir=\"C:/Users/negin/Jobinja Sorted Star\"):\n",
    "        self.base_url = base_url\n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
    "        }\n",
    "        self.save_dir = save_dir\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "        self.all_jobs_data = []\n",
    "        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "    def get_links(self):\n",
    "        try:\n",
    "            response = requests.get(self.base_url, headers=self.headers, verify=False, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            links = soup.find_all('a', href=True)\n",
    "            subpage_links = Queue()\n",
    "            unique_links = set()\n",
    "\n",
    "            for link in links:\n",
    "                href = link['href']\n",
    "                if href.startswith('/'):\n",
    "                    full_url = self.base_url + href\n",
    "                elif href.startswith('http'):\n",
    "                    full_url = href\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                if full_url not in unique_links:\n",
    "                    subpage_links.put(full_url)\n",
    "                    unique_links.add(full_url)\n",
    "\n",
    "            return subpage_links\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logger.error(f\"An error occurred while getting links: {e}\")\n",
    "            return Queue()\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_persian_text(text):\n",
    "        cleaned_text = re.sub(r'[^؀-ۿ\\s]', ' ', text)\n",
    "        cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "        return cleaned_text.strip()\n",
    "\n",
    "    def extract_job_features(self, subpage_soup):\n",
    "        job_features = {}\n",
    "        job_title_tag = subpage_soup.find('h1')\n",
    "        if job_title_tag:\n",
    "            job_features['job_title'] = self.clean_persian_text(job_title_tag.get_text())\n",
    "\n",
    "        job_description_tag = subpage_soup.find('div', class_='job-description')\n",
    "        if job_description_tag:\n",
    "            job_features['job_description'] = self.clean_persian_text(job_description_tag.get_text())\n",
    "        \n",
    "        additional_features = {\n",
    "            'job_category': ('div', 'job-category'),\n",
    "            'job_location': ('div', 'job-location'),\n",
    "            'employment_type': ('div', 'employment-type'),\n",
    "            'min_experience': ('div', 'min-experience'),\n",
    "            'salary': ('div', 'salary'),\n",
    "            'gender': ('div', 'gender'),\n",
    "            'military_status': ('div', 'military-status'),\n",
    "            'education_level': ('div', 'education-level'),\n",
    "            'company_intro': ('div', 'company-intro'),\n",
    "            'skills_required': ('div', 'skills-required'),\n",
    "        }\n",
    "\n",
    "        for feature, (tag, class_name) in additional_features.items():\n",
    "            feature_tag = subpage_soup.find(tag, class_=class_name)\n",
    "            if feature_tag:\n",
    "                job_features[feature] = self.clean_persian_text(feature_tag.get_text())\n",
    "\n",
    "        job_features['content_snippet'] = self.clean_persian_text(subpage_soup.get_text())\n",
    "        return job_features\n",
    "\n",
    "    def scrape_jobs(self):\n",
    "        subpage_links = self.get_links()\n",
    "\n",
    "        while not subpage_links.empty():\n",
    "            subpage_url = subpage_links.get()\n",
    "            try:\n",
    "                subpage_response = requests.get(subpage_url, headers=self.headers, verify=False, timeout=10)\n",
    "                subpage_response.raise_for_status()\n",
    "                subpage_soup = BeautifulSoup(subpage_response.text, 'html.parser')\n",
    "                job_data = self.extract_job_features(subpage_soup)\n",
    "\n",
    "                if job_data:\n",
    "                    self.all_jobs_data.append(job_data)\n",
    "                    self.save_job_as_text(job_data)\n",
    "\n",
    "                time.sleep(1)\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                logger.error(f\"An error occurred while accessing {subpage_url}: {e}\")\n",
    "\n",
    "    def save_job_as_text(self, job_data):\n",
    "        job_title = job_data.get('job_title', 'JobInja')\n",
    "        file_path = os.path.join(self.save_dir, f\"{job_title}.txt\")\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            content = (\n",
    "                f\"عنوان شغلی: {job_data.get('job_title', 'اطلاعات موجود نیست')}\\n\"\n",
    "                f\"نوع شغل: {job_data.get('employment_type', 'اطلاعات موجود نیست')}\\n\"\n",
    "                f\"موقعیت مکانی: {job_data.get('job_location', 'اطلاعات موجود نیست')}\\n\"\n",
    "                f\"اسم شرکت: {job_data.get('company_intro', 'اطلاعات موجود نیست')}\\n\"\n",
    "                f\"جنسیت: {job_data.get('gender', 'اطلاعات موجود نیست')}\\n\"\n",
    "                f\"سطح تحصیلات: {job_data.get('education_level', 'اطلاعات موجود نیست')}\\n\"\n",
    "                f\"حقوق: {job_data.get('salary', 'اطلاعات موجود نیست')}\\n\"\n",
    "                f\"\\nمتن آگهی:\\n{job_data.get('job_description', 'اطلاعات موجود نیست')}\\n\"\n",
    "            )\n",
    "            file.write(content)\n",
    "\n",
    "    def save_dataset(self):\n",
    "        mat_file_path = os.path.join(self.save_dir, \"jobinja_data.mat\")\n",
    "        json_file_path = os.path.join(self.save_dir, \"jobinja_data.json\")\n",
    "        job_data_dict = {f\"job_{i}\": job for i, job in enumerate(self.all_jobs_data)}\n",
    "        sio.savemat(mat_file_path, job_data_dict)\n",
    "        with open(json_file_path, 'w', encoding='utf-8') as json_file:\n",
    "            json.dump(self.all_jobs_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    def display_dataset(self):\n",
    "        df = pd.DataFrame(self.all_jobs_data)\n",
    "        print(df)\n",
    "        return df\n",
    "\n",
    "    def descriptive_statistics(self):\n",
    "        df = pd.DataFrame(self.all_jobs_data)\n",
    "        if not df.empty:\n",
    "            print(df.describe(include='all'))\n",
    "        else:\n",
    "            print(\"No data available to generate statistics.\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    jobinja_scraper = Jobinja()\n",
    "    jobinja_scraper.scrape_jobs()\n",
    "    jobinja_scraper.save_dataset()\n",
    "    df = jobinja_scraper.display_dataset()\n",
    "    jobinja_scraper.descriptive_statistics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53634e7-3dd0-407b-8ac7-09c0b0798574",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
